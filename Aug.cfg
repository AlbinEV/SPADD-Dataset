[net]
batch=8
subdivisions=4
height=320
width=320
channels=3
#letter_box=1

# Learning
momentum=0.9
decay=0.0005
learning_rate=0.001
# Dopo quanto calcola mAP
burn_in = 100
max_batches = 500000
policy=steps
steps = 200000,250000
scales=.1,.1
# policy=random

# Data Augmentation
angle=0
saturation = 1.5
exposure = 1.5
hue=.1
# blur=5
aspect=.75
# mosaic=1
# gaussian_noise=1

[convolutional]
batch_normalize=1
filters=16
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=18
activation=linear

[yolo]
mask = 0,1,2
anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319
classes=1
num=6
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1
